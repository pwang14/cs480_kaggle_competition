{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMO5fpi2g81pYvr9mKwAi1z"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"standard","accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"2eb98b80479b4ffdaecdb0eaaab3820d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_aaec6ae783664e23a0fdc983cebca623","IPY_MODEL_6e95e085d4334418815adff23bb27d3b","IPY_MODEL_8e6520ee8c0741fbbdaa8421cba5439f"],"layout":"IPY_MODEL_deb20e101d024cbf9198eac1723ea7f2"}},"aaec6ae783664e23a0fdc983cebca623":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a7b0628d2e464137a23840471b9ba591","placeholder":"​","style":"IPY_MODEL_c89b41ffeb314927bf0441144371cc41","value":"Downloading (…)solve/main/vocab.txt: 100%"}},"6e95e085d4334418815adff23bb27d3b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d7f2567005b14ba5adc213f95b9e66b8","max":213450,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d72912dc0a2c496394d728aaa2dd40b4","value":213450}},"8e6520ee8c0741fbbdaa8421cba5439f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d776523279834fa8af6e99791358bb9b","placeholder":"​","style":"IPY_MODEL_4fcfa6cbc93e439993529b91e4657999","value":" 213k/213k [00:00&lt;00:00, 1.71MB/s]"}},"deb20e101d024cbf9198eac1723ea7f2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a7b0628d2e464137a23840471b9ba591":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c89b41ffeb314927bf0441144371cc41":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d7f2567005b14ba5adc213f95b9e66b8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d72912dc0a2c496394d728aaa2dd40b4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d776523279834fa8af6e99791358bb9b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4fcfa6cbc93e439993529b91e4657999":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d5c11a7441234622888c39a421e6efc4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_980bd92065f44442b58a5ad9ed12c99c","IPY_MODEL_6fec93bd53b64a18bc1d842308c35683","IPY_MODEL_f10ee493edc54fb6a781a72a164f084c"],"layout":"IPY_MODEL_cb22d71d79c6444ab234b3cac02d8b72"}},"980bd92065f44442b58a5ad9ed12c99c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1ba95ef363464cd58efefd7aba430eaa","placeholder":"​","style":"IPY_MODEL_bb2eb0fd8b09426ba6d68caa86f89cd7","value":"Downloading (…)okenizer_config.json: 100%"}},"6fec93bd53b64a18bc1d842308c35683":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6f18128928e54f9f9552bbb2a7441c46","max":29,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fe50a6339e9847b196b7a5e2cfd6fb3e","value":29}},"f10ee493edc54fb6a781a72a164f084c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6aa8a49dfd8e498482dab991caa34be3","placeholder":"​","style":"IPY_MODEL_b81de4932fe64c3482a42af3ab5795d7","value":" 29.0/29.0 [00:00&lt;00:00, 1.25kB/s]"}},"cb22d71d79c6444ab234b3cac02d8b72":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1ba95ef363464cd58efefd7aba430eaa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bb2eb0fd8b09426ba6d68caa86f89cd7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6f18128928e54f9f9552bbb2a7441c46":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fe50a6339e9847b196b7a5e2cfd6fb3e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6aa8a49dfd8e498482dab991caa34be3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b81de4932fe64c3482a42af3ab5795d7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4ceade28419c42d8814c3d9bbb6331d1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c5305ce4f41a4bba9ad24524468f3cd4","IPY_MODEL_4540d5fcd3bf4ab09873917853fbd4b9","IPY_MODEL_9329f9c4c8df4dc4b3b76e8ab47aa344"],"layout":"IPY_MODEL_319b8a11cab243af88b68ceaeed403ab"}},"c5305ce4f41a4bba9ad24524468f3cd4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a4942f07fee84d5289ca89d2a361bcfe","placeholder":"​","style":"IPY_MODEL_daacdd7bbcf04184b3beca638c9ad91b","value":"Downloading (…)lve/main/config.json: 100%"}},"4540d5fcd3bf4ab09873917853fbd4b9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_df260d8ad40d42eaa3c1dd8f45c13777","max":411,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6bb88fc158894bd1b7e988028b9f601f","value":411}},"9329f9c4c8df4dc4b3b76e8ab47aa344":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3e03e12963ef42b7b54613562c6793df","placeholder":"​","style":"IPY_MODEL_be4d45d282844b3bb38b3002270e1b0a","value":" 411/411 [00:00&lt;00:00, 24.4kB/s]"}},"319b8a11cab243af88b68ceaeed403ab":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a4942f07fee84d5289ca89d2a361bcfe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"daacdd7bbcf04184b3beca638c9ad91b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"df260d8ad40d42eaa3c1dd8f45c13777":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6bb88fc158894bd1b7e988028b9f601f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3e03e12963ef42b7b54613562c6793df":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"be4d45d282844b3bb38b3002270e1b0a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0125b4de6ff34346b5d6ece1d782dac6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_265ee63600e3442eb817add0b5a87fa7","IPY_MODEL_0c8fdc7e48254391ac0e0b2cd6625d89","IPY_MODEL_d716937f354d4ffa9dc6afda480ec1c4"],"layout":"IPY_MODEL_b918620a22c946799488d93b765a8f51"}},"265ee63600e3442eb817add0b5a87fa7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_33e4f9a2fda44f829bf3dac1e2798f52","placeholder":"​","style":"IPY_MODEL_2bc3006c60c14dd782f3b3f45c1fbe92","value":"Downloading (…)lve/main/config.json: 100%"}},"0c8fdc7e48254391ac0e0b2cd6625d89":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_15eed32cd8294f7f9183302cedbd14e5","max":483,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c6eedaaa67dd4689866d7d5c4030de77","value":483}},"d716937f354d4ffa9dc6afda480ec1c4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a93ad4550e124134bc8c0953cd9c66d8","placeholder":"​","style":"IPY_MODEL_576ad75a746c46fe9f2f07c862de4e13","value":" 483/483 [00:00&lt;00:00, 17.5kB/s]"}},"b918620a22c946799488d93b765a8f51":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"33e4f9a2fda44f829bf3dac1e2798f52":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2bc3006c60c14dd782f3b3f45c1fbe92":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"15eed32cd8294f7f9183302cedbd14e5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c6eedaaa67dd4689866d7d5c4030de77":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a93ad4550e124134bc8c0953cd9c66d8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"576ad75a746c46fe9f2f07c862de4e13":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5c04e42fdc0c4788adbc4ee8a882352a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_42d724abb2834c61908aedf377159dcc","IPY_MODEL_657f6409942c44de81c8780063bfc0f1","IPY_MODEL_964cf14b9a5043c0839816673c453110"],"layout":"IPY_MODEL_d5c8264d015a4bd9a2caa9a6dc8ba5a4"}},"42d724abb2834c61908aedf377159dcc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7b67d403fb48446bac82ff7916ff3217","placeholder":"​","style":"IPY_MODEL_d8970686771c4b73a17f9cde261e91d6","value":"Downloading pytorch_model.bin: 100%"}},"657f6409942c44de81c8780063bfc0f1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_389f06f2c8d74f0a829583d7f9d27b4a","max":267967963,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4513e69709e744978c09f0a96f6ad4da","value":267967963}},"964cf14b9a5043c0839816673c453110":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_96c2ac77e52f45f8b0a8a921059ccea7","placeholder":"​","style":"IPY_MODEL_5f47b767aa204017a42e1bc86d9425e5","value":" 268M/268M [00:01&lt;00:00, 188MB/s]"}},"d5c8264d015a4bd9a2caa9a6dc8ba5a4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7b67d403fb48446bac82ff7916ff3217":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d8970686771c4b73a17f9cde261e91d6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"389f06f2c8d74f0a829583d7f9d27b4a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4513e69709e744978c09f0a96f6ad4da":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"96c2ac77e52f45f8b0a8a921059ccea7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5f47b767aa204017a42e1bc86d9425e5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LlxkTJGSXhF5","executionInfo":{"status":"ok","timestamp":1681334379019,"user_tz":240,"elapsed":22789,"user":{"displayName":"Patrick Wang","userId":"09514208081734500853"}},"outputId":"afd54a0a-4ecc-4281-e70f-d3047d54e522"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.27.4-py3-none-any.whl (6.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m60.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting datasets\n","  Downloading datasets-2.11.0-py3-none-any.whl (468 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.7/468.7 kB\u001b[0m \u001b[31m44.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting evaluate\n","  Downloading evaluate-0.4.0-py3-none-any.whl (81 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.4/81.4 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.0)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n","  Downloading tokenizers-0.13.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m63.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.27.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n","Collecting huggingface-hub<1.0,>=0.11.0\n","  Downloading huggingface_hub-0.13.4-py3-none-any.whl (200 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.1/200.1 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.11.0)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from datasets) (1.5.3)\n","Collecting dill<0.3.7,>=0.3.0\n","  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting responses<0.19\n","  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n","Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.9/dist-packages (from datasets) (2023.3.0)\n","Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.9/dist-packages (from datasets) (9.0.0)\n","Collecting multiprocess\n","  Downloading multiprocess-0.70.14-py39-none-any.whl (132 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.9/132.9 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting xxhash\n","  Downloading xxhash-3.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.2/212.2 kB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting aiohttp\n","  Downloading aiohttp-3.8.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m69.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting aiosignal>=1.1.2\n","  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (22.2.0)\n","Collecting multidict<7.0,>=4.5\n","  Downloading multidict-6.0.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.2/114.2 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n","  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n","Collecting yarl<2.0,>=1.0\n","  Downloading yarl-1.8.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (264 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.6/264.6 kB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (2.0.12)\n","Collecting frozenlist>=1.1.1\n","  Downloading frozenlist-1.3.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (158 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 kB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->datasets) (2022.7.1)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n","Installing collected packages: tokenizers, xxhash, multidict, frozenlist, dill, async-timeout, yarl, responses, multiprocess, huggingface-hub, aiosignal, transformers, aiohttp, datasets, evaluate\n","Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 datasets-2.11.0 dill-0.3.6 evaluate-0.4.0 frozenlist-1.3.3 huggingface-hub-0.13.4 multidict-6.0.4 multiprocess-0.70.14 responses-0.18.0 tokenizers-0.13.3 transformers-4.27.4 xxhash-3.2.0 yarl-1.8.2\n"]}],"source":["!pip install transformers datasets evaluate"]},{"cell_type":"code","source":["# Importing the libraries needed\n","import pandas as pd\n","import torch\n","import transformers\n","from torch.utils.data import Dataset, DataLoader\n","from transformers import DistilBertModel, DistilBertTokenizer"],"metadata":{"id":"wRcHCD52Tbdt","executionInfo":{"status":"ok","timestamp":1681334388314,"user_tz":240,"elapsed":9298,"user":{"displayName":"Patrick Wang","userId":"09514208081734500853"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# Setting up the device for GPU usage\n","\n","from torch import cuda\n","device = 'cuda' if cuda.is_available() else 'cpu'"],"metadata":{"id":"2nB_84bSTfRJ","executionInfo":{"status":"ok","timestamp":1681334388593,"user_tz":240,"elapsed":280,"user":{"displayName":"Patrick Wang","userId":"09514208081734500853"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# Import the csv into pandas dataframe and add the headers\n","# df = pd.read_csv('./data/newsCorpora.csv', sep='\\t', names=['ID','TITLE', 'URL', 'PUBLISHER', 'CATEGORY', 'STORY', 'HOSTNAME', 'TIMESTAMP'])\n","df = pd.read_csv('train.csv')\n","# df.head()\n","# # Removing unwanted columns and only leaving title of news and the category which will be the target\n","# df = df[['TITLE','CATEGORY']]\n","df = df[['category', 'noisyTextDescription']]\n","# df.head()\n","\n","# # Converting the codes to appropriate categories using a dictionary\n","# my_dict = {\n","#     'e':'Entertainment',\n","#     'b':'Business',\n","#     't':'Science',\n","#     'm':'Health'\n","# }\n","\n","# def update_cat(x):\n","#     return my_dict[x]\n","\n","# df['CATEGORY'] = df['CATEGORY'].apply(lambda x: update_cat(x))\n","\n","encode_dict = {}\n","\n","def encode_cat(x):\n","    if x not in encode_dict.keys():\n","        encode_dict[x]=len(encode_dict)\n","    return encode_dict[x]\n","\n","df['encode_cat'] = df['category'].apply(lambda x: encode_cat(x))"],"metadata":{"id":"3jFzVr5wTgXc","executionInfo":{"status":"ok","timestamp":1681334388593,"user_tz":240,"elapsed":2,"user":{"displayName":"Patrick Wang","userId":"09514208081734500853"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["NUM_CATEGORIES = len(encode_dict)"],"metadata":{"id":"tXj99VM6VGtx","executionInfo":{"status":"ok","timestamp":1681334388593,"user_tz":240,"elapsed":2,"user":{"displayName":"Patrick Wang","userId":"09514208081734500853"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# Defining some key variables that will be used later on in the training\n","MAX_LEN = 512\n","TRAIN_BATCH_SIZE = 4\n","VALID_BATCH_SIZE = 2\n","EPOCHS = 1\n","LEARNING_RATE = 1e-05\n","tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-cased')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":113,"referenced_widgets":["2eb98b80479b4ffdaecdb0eaaab3820d","aaec6ae783664e23a0fdc983cebca623","6e95e085d4334418815adff23bb27d3b","8e6520ee8c0741fbbdaa8421cba5439f","deb20e101d024cbf9198eac1723ea7f2","a7b0628d2e464137a23840471b9ba591","c89b41ffeb314927bf0441144371cc41","d7f2567005b14ba5adc213f95b9e66b8","d72912dc0a2c496394d728aaa2dd40b4","d776523279834fa8af6e99791358bb9b","4fcfa6cbc93e439993529b91e4657999","d5c11a7441234622888c39a421e6efc4","980bd92065f44442b58a5ad9ed12c99c","6fec93bd53b64a18bc1d842308c35683","f10ee493edc54fb6a781a72a164f084c","cb22d71d79c6444ab234b3cac02d8b72","1ba95ef363464cd58efefd7aba430eaa","bb2eb0fd8b09426ba6d68caa86f89cd7","6f18128928e54f9f9552bbb2a7441c46","fe50a6339e9847b196b7a5e2cfd6fb3e","6aa8a49dfd8e498482dab991caa34be3","b81de4932fe64c3482a42af3ab5795d7","4ceade28419c42d8814c3d9bbb6331d1","c5305ce4f41a4bba9ad24524468f3cd4","4540d5fcd3bf4ab09873917853fbd4b9","9329f9c4c8df4dc4b3b76e8ab47aa344","319b8a11cab243af88b68ceaeed403ab","a4942f07fee84d5289ca89d2a361bcfe","daacdd7bbcf04184b3beca638c9ad91b","df260d8ad40d42eaa3c1dd8f45c13777","6bb88fc158894bd1b7e988028b9f601f","3e03e12963ef42b7b54613562c6793df","be4d45d282844b3bb38b3002270e1b0a"]},"id":"F795QGomThfJ","executionInfo":{"status":"ok","timestamp":1681334390035,"user_tz":240,"elapsed":1248,"user":{"displayName":"Patrick Wang","userId":"09514208081734500853"}},"outputId":"b45e924e-9e08-4d73-fefa-71f9d6a39e82"},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2eb98b80479b4ffdaecdb0eaaab3820d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)okenizer_config.json:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d5c11a7441234622888c39a421e6efc4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/411 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4ceade28419c42d8814c3d9bbb6331d1"}},"metadata":{}}]},{"cell_type":"code","source":["class Triage(Dataset):\n","    def __init__(self, dataframe, tokenizer, max_len):\n","        self.len = len(dataframe)\n","        self.data = dataframe\n","        self.tokenizer = tokenizer\n","        self.max_len = max_len\n","        \n","    def __getitem__(self, index):\n","        title = str(self.data.noisyTextDescription[index])\n","        title = \" \".join(title.split())\n","        inputs = self.tokenizer.encode_plus(\n","            title,\n","            None,\n","            add_special_tokens=True,\n","            max_length=self.max_len,\n","            pad_to_max_length=True,\n","            return_token_type_ids=True,\n","            truncation=True\n","        )\n","        ids = inputs['input_ids']\n","        mask = inputs['attention_mask']\n","\n","        return {\n","            'ids': torch.tensor(ids, dtype=torch.long),\n","            'mask': torch.tensor(mask, dtype=torch.long),\n","            'targets': torch.tensor(self.data.encode_cat[index], dtype=torch.long)\n","        } \n","    \n","    def __len__(self):\n","        return self.len"],"metadata":{"id":"K71fnszWTiPb","executionInfo":{"status":"ok","timestamp":1681334390035,"user_tz":240,"elapsed":6,"user":{"displayName":"Patrick Wang","userId":"09514208081734500853"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["# Creating the dataset and dataloader for the neural network\n","\n","train_size = 0.8\n","train_dataset=df.sample(frac=train_size,random_state=200)\n","test_dataset=df.drop(train_dataset.index).reset_index(drop=True)\n","train_dataset = train_dataset.reset_index(drop=True)\n","\n","\n","print(\"FULL Dataset: {}\".format(df.shape))\n","print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n","print(\"TEST Dataset: {}\".format(test_dataset.shape))\n","\n","training_set = Triage(train_dataset, tokenizer, MAX_LEN)\n","testing_set = Triage(test_dataset, tokenizer, MAX_LEN)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B1e8NlaRTjat","executionInfo":{"status":"ok","timestamp":1681334390036,"user_tz":240,"elapsed":6,"user":{"displayName":"Patrick Wang","userId":"09514208081734500853"}},"outputId":"bdfb4702-5902-4ac8-937a-02cb1dc713e5"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["FULL Dataset: (21627, 3)\n","TRAIN Dataset: (17302, 3)\n","TEST Dataset: (4325, 3)\n"]}]},{"cell_type":"code","source":["train_params = {'batch_size': TRAIN_BATCH_SIZE,\n","                'shuffle': True,\n","                'num_workers': 0\n","                }\n","\n","test_params = {'batch_size': VALID_BATCH_SIZE,\n","                'shuffle': True,\n","                'num_workers': 0\n","                }\n","\n","training_loader = DataLoader(training_set, **train_params)\n","testing_loader = DataLoader(testing_set, **test_params)"],"metadata":{"id":"GNEcsGcLTkSD","executionInfo":{"status":"ok","timestamp":1681334390036,"user_tz":240,"elapsed":5,"user":{"displayName":"Patrick Wang","userId":"09514208081734500853"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["# Creating the customized model, by adding a drop out and a dense layer on top of distil bert to get the final output for the model. \n","\n","class DistillBERTClass(torch.nn.Module):\n","    def __init__(self):\n","        super(DistillBERTClass, self).__init__()\n","        self.l1 = DistilBertModel.from_pretrained(\"distilbert-base-uncased\")\n","        self.pre_classifier = torch.nn.Linear(768, 768)\n","        self.dropout = torch.nn.Dropout(0.3)\n","        self.classifier = torch.nn.Linear(768, NUM_CATEGORIES)\n","\n","    def forward(self, input_ids, attention_mask):\n","        output_1 = self.l1(input_ids=input_ids, attention_mask=attention_mask)\n","        hidden_state = output_1[0]\n","        pooler = hidden_state[:, 0]\n","        pooler = self.pre_classifier(pooler)\n","        pooler = torch.nn.ReLU()(pooler)\n","        pooler = self.dropout(pooler)\n","        output = self.classifier(pooler)\n","        return output"],"metadata":{"id":"lOMZJUNQTlQR","executionInfo":{"status":"ok","timestamp":1681334390036,"user_tz":240,"elapsed":4,"user":{"displayName":"Patrick Wang","userId":"09514208081734500853"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["model = DistillBERTClass()\n","model.to(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":743,"referenced_widgets":["0125b4de6ff34346b5d6ece1d782dac6","265ee63600e3442eb817add0b5a87fa7","0c8fdc7e48254391ac0e0b2cd6625d89","d716937f354d4ffa9dc6afda480ec1c4","b918620a22c946799488d93b765a8f51","33e4f9a2fda44f829bf3dac1e2798f52","2bc3006c60c14dd782f3b3f45c1fbe92","15eed32cd8294f7f9183302cedbd14e5","c6eedaaa67dd4689866d7d5c4030de77","a93ad4550e124134bc8c0953cd9c66d8","576ad75a746c46fe9f2f07c862de4e13","5c04e42fdc0c4788adbc4ee8a882352a","42d724abb2834c61908aedf377159dcc","657f6409942c44de81c8780063bfc0f1","964cf14b9a5043c0839816673c453110","d5c8264d015a4bd9a2caa9a6dc8ba5a4","7b67d403fb48446bac82ff7916ff3217","d8970686771c4b73a17f9cde261e91d6","389f06f2c8d74f0a829583d7f9d27b4a","4513e69709e744978c09f0a96f6ad4da","96c2ac77e52f45f8b0a8a921059ccea7","5f47b767aa204017a42e1bc86d9425e5"]},"id":"y_YQjTGLTmQx","executionInfo":{"status":"ok","timestamp":1681334401755,"user_tz":240,"elapsed":11723,"user":{"displayName":"Patrick Wang","userId":"09514208081734500853"}},"outputId":"c53004ee-208c-42ad-8cbe-d745d742ee14"},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0125b4de6ff34346b5d6ece1d782dac6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/268M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5c04e42fdc0c4788adbc4ee8a882352a"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_transform.weight', 'vocab_projector.bias']\n","- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"execute_result","data":{"text/plain":["DistillBERTClass(\n","  (l1): DistilBertModel(\n","    (embeddings): Embeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (transformer): Transformer(\n","      (layer): ModuleList(\n","        (0-5): 6 x TransformerBlock(\n","          (attention): MultiHeadSelfAttention(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (ffn): FFN(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n","            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n","            (activation): GELUActivation()\n","          )\n","          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        )\n","      )\n","    )\n","  )\n","  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n","  (dropout): Dropout(p=0.3, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=27, bias=True)\n",")"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["# Creating the loss function and optimizer\n","loss_function = torch.nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(params =  model.parameters(), lr=LEARNING_RATE)"],"metadata":{"id":"ZmO6s-4LTm4-","executionInfo":{"status":"ok","timestamp":1681334401756,"user_tz":240,"elapsed":4,"user":{"displayName":"Patrick Wang","userId":"09514208081734500853"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["# Function to calcuate the accuracy of the model\n","\n","def calcuate_accu(big_idx, targets):\n","    n_correct = (big_idx==targets).sum().item()\n","    return n_correct"],"metadata":{"id":"aeq40dnyToI7","executionInfo":{"status":"ok","timestamp":1681334401756,"user_tz":240,"elapsed":3,"user":{"displayName":"Patrick Wang","userId":"09514208081734500853"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["# Defining the training function on the 80% of the dataset for tuning the distilbert model\n","\n","def train(epoch):\n","    tr_loss = 0\n","    n_correct = 0\n","    nb_tr_steps = 0\n","    nb_tr_examples = 0\n","    model.train()\n","    for _,data in enumerate(training_loader, 0):\n","        ids = data['ids'].to(device, dtype = torch.long)\n","        mask = data['mask'].to(device, dtype = torch.long)\n","        targets = data['targets'].to(device, dtype = torch.long)\n","\n","        outputs = model(ids, mask)\n","        loss = loss_function(outputs, targets)\n","        tr_loss += loss.item()\n","        big_val, big_idx = torch.max(outputs.data, dim=1)\n","        n_correct += calcuate_accu(big_idx, targets)\n","\n","        nb_tr_steps += 1\n","        nb_tr_examples+=targets.size(0)\n","        \n","        if _%100==0:\n","            loss_step = tr_loss/nb_tr_steps\n","            accu_step = (n_correct*100)/nb_tr_examples \n","            print(f\"Training Loss per 100 steps: {loss_step}\")\n","            print(f\"Training Accuracy per 100 steps: {accu_step}\")\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        # # When using GPU\n","        optimizer.step()\n","\n","    print(f'The Total Accuracy for Epoch {epoch}: {(n_correct*100)/nb_tr_examples}')\n","    epoch_loss = tr_loss/nb_tr_steps\n","    epoch_accu = (n_correct*100)/nb_tr_examples\n","    print(f\"Training Loss Epoch: {epoch_loss}\")\n","    print(f\"Training Accuracy Epoch: {epoch_accu}\")\n","\n","    return "],"metadata":{"id":"SDsgzpgDTo_T","executionInfo":{"status":"ok","timestamp":1681334574957,"user_tz":240,"elapsed":347,"user":{"displayName":"Patrick Wang","userId":"09514208081734500853"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["for epoch in range(EPOCHS):\n","    train(epoch)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3KL_Tcd5Tp68","executionInfo":{"status":"ok","timestamp":1681335453357,"user_tz":240,"elapsed":877514,"user":{"displayName":"Patrick Wang","userId":"09514208081734500853"}},"outputId":"11aed920-e8cc-4206-d2aa-26cb2ca8cb81"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Training Loss per 100 steps: 1.7249985933303833\n","Training Accuracy per 100 steps: 50.0\n","Training Loss per 100 steps: 1.7913762165768312\n","Training Accuracy per 100 steps: 54.20792079207921\n","Training Loss per 100 steps: 1.8023425852926216\n","Training Accuracy per 100 steps: 55.472636815920396\n","Training Loss per 100 steps: 1.7671549383092957\n","Training Accuracy per 100 steps: 56.81063122923588\n","Training Loss per 100 steps: 1.7211507552505432\n","Training Accuracy per 100 steps: 57.98004987531172\n","Training Loss per 100 steps: 1.6819196656911435\n","Training Accuracy per 100 steps: 59.231536926147704\n","Training Loss per 100 steps: 1.6464695735600545\n","Training Accuracy per 100 steps: 60.56572379367721\n","Training Loss per 100 steps: 1.6054334724255532\n","Training Accuracy per 100 steps: 61.84022824536377\n","Training Loss per 100 steps: 1.5653174461868966\n","Training Accuracy per 100 steps: 62.92134831460674\n","Training Loss per 100 steps: 1.5359616835460017\n","Training Accuracy per 100 steps: 63.73473917869035\n","Training Loss per 100 steps: 1.5262720944224062\n","Training Accuracy per 100 steps: 64.03596403596404\n","Training Loss per 100 steps: 1.5109924854918786\n","Training Accuracy per 100 steps: 64.48683015440508\n","Training Loss per 100 steps: 1.5092262407511994\n","Training Accuracy per 100 steps: 64.63363863447127\n","Training Loss per 100 steps: 1.484671998021696\n","Training Accuracy per 100 steps: 65.23827824750192\n","Training Loss per 100 steps: 1.4714388464132775\n","Training Accuracy per 100 steps: 65.70306923625981\n","Training Loss per 100 steps: 1.465067318440238\n","Training Accuracy per 100 steps: 65.80612924716856\n","Training Loss per 100 steps: 1.4489361996402375\n","Training Accuracy per 100 steps: 66.19300437226734\n","Training Loss per 100 steps: 1.4393486912192\n","Training Accuracy per 100 steps: 66.62257495590829\n","Training Loss per 100 steps: 1.4226475289253842\n","Training Accuracy per 100 steps: 66.99056079955581\n","Training Loss per 100 steps: 1.415320192235887\n","Training Accuracy per 100 steps: 67.1488690163072\n","Training Loss per 100 steps: 1.4075892716720664\n","Training Accuracy per 100 steps: 67.41629185407297\n","Training Loss per 100 steps: 1.3965663855477835\n","Training Accuracy per 100 steps: 67.6582579723941\n","Training Loss per 100 steps: 1.3925210699330726\n","Training Accuracy per 100 steps: 67.88959563834621\n","Training Loss per 100 steps: 1.382883110703307\n","Training Accuracy per 100 steps: 68.17687961755759\n","Training Loss per 100 steps: 1.381563525549177\n","Training Accuracy per 100 steps: 68.27363598500625\n","Training Loss per 100 steps: 1.3734483288102797\n","Training Accuracy per 100 steps: 68.58256697321072\n","Training Loss per 100 steps: 1.3640770575619579\n","Training Accuracy per 100 steps: 68.82929642445214\n","Training Loss per 100 steps: 1.351242451869594\n","Training Accuracy per 100 steps: 69.16882636060718\n","Training Loss per 100 steps: 1.3409474336970113\n","Training Accuracy per 100 steps: 69.40378436272759\n","Training Loss per 100 steps: 1.3352034892713518\n","Training Accuracy per 100 steps: 69.51913133402275\n","Training Loss per 100 steps: 1.3290913931824333\n","Training Accuracy per 100 steps: 69.6434521826058\n","Training Loss per 100 steps: 1.3250728081004806\n","Training Accuracy per 100 steps: 69.81618832634634\n","Training Loss per 100 steps: 1.320628878947665\n","Training Accuracy per 100 steps: 69.90784129959388\n","Training Loss per 100 steps: 1.317229585270111\n","Training Accuracy per 100 steps: 70.00151469251742\n","Training Loss per 100 steps: 1.308950920005172\n","Training Accuracy per 100 steps: 70.14848573948838\n","Training Loss per 100 steps: 1.3035904090788766\n","Training Accuracy per 100 steps: 70.28706083976007\n","Training Loss per 100 steps: 1.2970374750883273\n","Training Accuracy per 100 steps: 70.4457095251319\n","Training Loss per 100 steps: 1.2937253776356936\n","Training Accuracy per 100 steps: 70.55525533639558\n","Training Loss per 100 steps: 1.2896220837355883\n","Training Accuracy per 100 steps: 70.63272822941332\n","Training Loss per 100 steps: 1.2840824291259012\n","Training Accuracy per 100 steps: 70.78313253012048\n","Training Loss per 100 steps: 1.2795245856329729\n","Training Accuracy per 100 steps: 70.89477630592351\n","Training Loss per 100 steps: 1.277065697233507\n","Training Accuracy per 100 steps: 70.92172640819312\n","Training Loss per 100 steps: 1.271693441934371\n","Training Accuracy per 100 steps: 71.04855986669841\n","Training Loss per 100 steps: 1.2681493713682652\n","Training Accuracy per 100 steps: 71.1578702627296\n","The Total Accuracy for Epoch 0: 71.1825222517628\n","Training Loss Epoch: 1.2675226474722474\n","Training Accuracy Epoch: 71.1825222517628\n"]}]},{"cell_type":"code","source":["def valid(model, testing_loader):\n","    model.eval()\n","    n_correct = 0; n_wrong = 0; total = 0\n","    tr_loss = 0\n","    nb_tr_steps = 0\n","    nb_tr_examples = 0\n","    with torch.no_grad():\n","        for _, data in enumerate(testing_loader, 0):\n","            ids = data['ids'].to(device, dtype = torch.long)\n","            mask = data['mask'].to(device, dtype = torch.long)\n","            targets = data['targets'].to(device, dtype = torch.long)\n","            outputs = model(ids, mask).squeeze()\n","            loss = loss_function(outputs, targets)\n","            tr_loss += loss.item()\n","            big_val, big_idx = torch.max(outputs.data, dim=1)\n","            n_correct += calcuate_accu(big_idx, targets)\n","\n","            nb_tr_steps += 1\n","            nb_tr_examples+=targets.size(0)\n","            \n","            if _%100==0:\n","                loss_step = tr_loss/nb_tr_steps\n","                accu_step = (n_correct*100)/nb_tr_examples\n","                print(f\"Validation Loss per 100 steps: {loss_step}\")\n","                print(f\"Validation Accuracy per 100 steps: {accu_step}\")\n","    epoch_loss = tr_loss/nb_tr_steps\n","    epoch_accu = (n_correct*100)/nb_tr_examples\n","    print(f\"Validation Loss Epoch: {epoch_loss}\")\n","    print(f\"Validation Accuracy Epoch: {epoch_accu}\")\n","    \n","    return epoch_accu\n"],"metadata":{"id":"sEF_Yf0fTq6s","executionInfo":{"status":"ok","timestamp":1681335580885,"user_tz":240,"elapsed":153,"user":{"displayName":"Patrick Wang","userId":"09514208081734500853"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["print('This is the validation section to print the accuracy and see how it performs')\n","print('Here we are leveraging on the dataloader crearted for the validation dataset, the approcah is using more of pytorch')\n","\n","acc = valid(model, testing_loader)\n","print(\"Accuracy on test data = %0.2f%%\" % acc)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"KmhlJ3KoTrwZ","executionInfo":{"status":"error","timestamp":1681335659561,"user_tz":240,"elapsed":77699,"user":{"displayName":"Patrick Wang","userId":"09514208081734500853"}},"outputId":"113783a5-a99f-456e-f336-b5824b7637ae"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["This is the validation section to print the accuracy and see how it performs\n","Here we are leveraging on the dataloader crearted for the validation dataset, the approcah is using more of pytorch\n","Validation Loss per 100 steps: 1.251245379447937\n","Validation Accuracy per 100 steps: 50.0\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:2346: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Validation Loss per 100 steps: 1.136500413538796\n","Validation Accuracy per 100 steps: 75.24752475247524\n","Validation Loss per 100 steps: 1.1780003362997848\n","Validation Accuracy per 100 steps: 74.12935323383084\n","Validation Loss per 100 steps: 1.176026630936271\n","Validation Accuracy per 100 steps: 74.4186046511628\n","Validation Loss per 100 steps: 1.1324862592442524\n","Validation Accuracy per 100 steps: 75.06234413965088\n","Validation Loss per 100 steps: 1.0876250431581054\n","Validation Accuracy per 100 steps: 76.24750499001996\n","Validation Loss per 100 steps: 1.095513837005999\n","Validation Accuracy per 100 steps: 76.37271214642263\n","Validation Loss per 100 steps: 1.0832101873490168\n","Validation Accuracy per 100 steps: 76.67617689015692\n","Validation Loss per 100 steps: 1.098886678616206\n","Validation Accuracy per 100 steps: 76.34207240948814\n","Validation Loss per 100 steps: 1.1027598477627143\n","Validation Accuracy per 100 steps: 76.19311875693674\n","Validation Loss per 100 steps: 1.0791728045646247\n","Validation Accuracy per 100 steps: 76.67332667332667\n","Validation Loss per 100 steps: 1.0730470018554394\n","Validation Accuracy per 100 steps: 76.65758401453225\n","Validation Loss per 100 steps: 1.0678718847925965\n","Validation Accuracy per 100 steps: 76.56119900083264\n","Validation Loss per 100 steps: 1.0668462923055746\n","Validation Accuracy per 100 steps: 76.47963105303613\n","Validation Loss per 100 steps: 1.0674990246113627\n","Validation Accuracy per 100 steps: 76.48108493932905\n","Validation Loss per 100 steps: 1.0597377016614231\n","Validation Accuracy per 100 steps: 76.68221185876082\n","Validation Loss per 100 steps: 1.071196446201062\n","Validation Accuracy per 100 steps: 76.48344784509682\n","Validation Loss per 100 steps: 1.0735763555380577\n","Validation Accuracy per 100 steps: 76.48442092886538\n","Validation Loss per 100 steps: 1.0678062391100758\n","Validation Accuracy per 100 steps: 76.56857301499167\n","Validation Loss per 100 steps: 1.0681107174223\n","Validation Accuracy per 100 steps: 76.59126775381378\n","Validation Loss per 100 steps: 1.0696688430204147\n","Validation Accuracy per 100 steps: 76.53673163418291\n","Validation Loss per 100 steps: 1.0683997653421193\n","Validation Accuracy per 100 steps: 76.60637791527844\n"]},{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-27-aa61109a5b1c>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Here we are leveraging on the dataloader crearted for the validation dataset, the approcah is using more of pytorch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtesting_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Accuracy on test data = %0.2f%%\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-26-f22e05b19228>\u001b[0m in \u001b[0;36mvalid\u001b[0;34m(model, testing_loader)\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'targets'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m             \u001b[0mtr_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mbig_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbig_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1173\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1174\u001b[0;31m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0m\u001b[1;32m   1175\u001b[0m                                \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m                                label_smoothing=self.label_smoothing)\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3027\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3028\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3029\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_smoothing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3030\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: size mismatch (got input: [27], target: [1])"]}]},{"cell_type":"code","source":["# import pandas as pd\n","# from datasets import Dataset\n","# import torch\n","# from torch import nn\n","# from torch.utils.data import Dataset, DataLoader\n","# import torch.nn.functional as F"],"metadata":{"id":"ndrIPJLxaWWy","executionInfo":{"status":"aborted","timestamp":1681334558885,"user_tz":240,"elapsed":6,"user":{"displayName":"Patrick Wang","userId":"09514208081734500853"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# from torch import cuda\n","# device = 'cuda' if cuda.is_available() else 'cpu'"],"metadata":{"id":"5jWK-4Y9PzwJ","executionInfo":{"status":"aborted","timestamp":1681334558885,"user_tz":240,"elapsed":6,"user":{"displayName":"Patrick Wang","userId":"09514208081734500853"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# from sklearn.model_selection import train_test_split\n","\n","# from transformers import DistilBertModel, DistilBertTokenizer\n","# tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-cased')"],"metadata":{"id":"jMxYmiiDxDt0","executionInfo":{"status":"aborted","timestamp":1681334558885,"user_tz":240,"elapsed":5,"user":{"displayName":"Patrick Wang","userId":"09514208081734500853"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# raw_data = pd.read_csv('train.csv')\n","# print(raw_data.iloc[1])\n","# train_texts = raw_data['noisyTextDescription']\n","# print(train_texts[1])\n","\n","# cat_2_ind = {}\n","# ind_2_cat = {}\n","# def convert_category(category):\n","#     if category not in cat_2_ind:\n","#         cat_2_ind[category] = len(cat_2_ind)\n","#         ind_2_cat[cat_2_ind[category]] = category\n","#     return cat_2_ind[category]\n","\n","# NUM_CATEGORIES = len(cat_2_ind)\n","\n","# train_labels = raw_data['category'].apply(convert_category)\n","# print(train_labels[1])\n","\n","# train_texts, val_texts, train_labels, val_labels = train_test_split(train_texts, train_labels, test_size=0.2)\n","# print(train_texts[0])\n","\n","# train_texts.reset_index(drop=True)\n","# val_texts.reset_index(drop=True)\n","# train_labels.reset_index(drop=True)\n","# val_labels.reset_index(drop=True)"],"metadata":{"id":"90j5Ajwcybd6","executionInfo":{"status":"aborted","timestamp":1681334558886,"user_tz":240,"elapsed":6,"user":{"displayName":"Patrick Wang","userId":"09514208081734500853"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# class DescriptionData(Dataset):\n","#     def __init__(self, texts, labels, tokenizer):\n","#         self.texts = texts\n","#         self.labels = labels\n","#         self.tokenizer = tokenizer\n","#         self.len = len(self.labels)\n","\n","#     def __getitem__(self, idx):\n","#         desc = self.texts.iloc[idx]\n","#         inputs = self.tokenizer.encode_plus(\n","#             desc,\n","#             None,\n","#             add_special_tokens=True,\n","#             max_length=512,\n","#             pad_to_max_length=True,\n","#             return_token_type_ids=True,\n","#             truncation=True\n","#         )\n","#         ids = inputs['input_ids']\n","#         mask = inputs['attention_mask']\n","\n","#         return {\n","#             'ids': torch.tensor(ids, dtype=torch.long),\n","#             'mask': torch.tensor(mask, dtype=torch.long),\n","#             'targets': torch.tensor(self.labels[idx], dtype=torch.long)\n","#         }\n","\n","#     def __len__(self):\n","#         return self.len\n","\n","# train_dataset = DescriptionData(train_texts, train_labels, tokenizer)\n","# val_dataset = DescriptionData(val_texts, val_labels, tokenizer)\n","\n","# TRAIN_BATCH_SIZE = 4\n","# VALID_BATCH_SIZE = 2\n","# EPOCHS = 1\n","# LEARNING_RATE = 1e-05\n","\n","# train_params = {\n","#     'batch_size': TRAIN_BATCH_SIZE,\n","#     'shuffle': True,\n","#     'num_workers': 0\n","#     }\n","\n","# val_params = {\n","#     'batch_size': VALID_BATCH_SIZE,\n","#     'shuffle': True,\n","#     'num_workers': 0\n","# }\n","\n","# train_loader = DataLoader(train_dataset, **train_params)\n","# val_loader = DataLoader(val_dataset, **val_params)"],"metadata":{"id":"RMMc-g2wcmvO","executionInfo":{"status":"aborted","timestamp":1681334558886,"user_tz":240,"elapsed":6,"user":{"displayName":"Patrick Wang","userId":"09514208081734500853"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# class BERTClass(nn.Module):\n","#     def __init__(self):\n","#         super(BERTClass, self).__init__()\n","#         self.bert = DistilBertModel.from_pretrained(\"distilbert-base-uncased\")\n","#         self.pre_classifier = torch.nn.Linear(768, 768)\n","#         self.dropout = torch.nn.Dropout(0.3)\n","#         self.classifier = torch.nn.Linear(768, NUM_CATEGORIES)\n","\n","#     def forward(self, input_ids, attention_mask):\n","#         output_1 = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n","#         hidden_state = output_1[0]\n","#         pooler = hidden_state[:, 0]\n","#         pooler = self.pre_classifier(pooler)\n","#         pooler = F.relu(pooler)\n","#         pooler = self.dropout(pooler)\n","#         output = self.classifier(pooler)\n","#         return output\n","\n","# model = BERTClass()\n","# model.to(device)"],"metadata":{"id":"tIOEVKwWL99S","executionInfo":{"status":"aborted","timestamp":1681334558886,"user_tz":240,"elapsed":6,"user":{"displayName":"Patrick Wang","userId":"09514208081734500853"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# loss_function = torch.nn.CrossEntropyLoss()\n","# optimizer = torch.optim.Adam(params =  model.parameters(), lr=LEARNING_RATE)"],"metadata":{"id":"Pk2DYR0UQYDY","executionInfo":{"status":"aborted","timestamp":1681334558887,"user_tz":240,"elapsed":7,"user":{"displayName":"Patrick Wang","userId":"09514208081734500853"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# def calcuate_accu(big_idx, targets):\n","#     n_correct = (big_idx==targets).sum().item()\n","#     return n_correct"],"metadata":{"id":"NA1tkN1-QgfE","executionInfo":{"status":"aborted","timestamp":1681334558887,"user_tz":240,"elapsed":7,"user":{"displayName":"Patrick Wang","userId":"09514208081734500853"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# def train(epoch):\n","#     tr_loss = 0\n","#     n_correct = 0\n","#     nb_tr_steps = 0\n","#     nb_tr_examples = 0\n","#     model.train()\n","#     for _,data in enumerate(train_loader, 0):\n","#         ids = data['ids'].to(device, dtype = torch.long)\n","#         mask = data['mask'].to(device, dtype = torch.long)\n","#         targets = data['targets'].to(device, dtype = torch.long)\n","\n","#         outputs = model(ids, mask)\n","#         loss = loss_function(outputs, targets)\n","#         tr_loss += loss.item()\n","#         big_val, big_idx = torch.max(outputs.data, dim=1)\n","#         n_correct += calcuate_accu(big_idx, targets)\n","\n","#         nb_tr_steps += 1\n","#         nb_tr_examples+=targets.size(0)\n","        \n","#         if _%5000==0:\n","#             loss_step = tr_loss/nb_tr_steps\n","#             accu_step = (n_correct*100)/nb_tr_examples \n","#             print(f\"Training Loss per 5000 steps: {loss_step}\")\n","#             print(f\"Training Accuracy per 5000 steps: {accu_step}\")\n","\n","#         optimizer.zero_grad()\n","#         loss.backward()\n","#         # # When using GPU\n","#         optimizer.step()\n","\n","#     print(f'The Total Accuracy for Epoch {epoch}: {(n_correct*100)/nb_tr_examples}')\n","#     epoch_loss = tr_loss/nb_tr_steps\n","#     epoch_accu = (n_correct*100)/nb_tr_examples\n","#     print(f\"Training Loss Epoch: {epoch_loss}\")\n","#     print(f\"Training Accuracy Epoch: {epoch_accu}\")\n","\n","#     return "],"metadata":{"id":"OP18c-9nQiEo","executionInfo":{"status":"aborted","timestamp":1681334558887,"user_tz":240,"elapsed":6,"user":{"displayName":"Patrick Wang","userId":"09514208081734500853"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# for epoch in range(EPOCHS):\n","#     train(epoch)"],"metadata":{"id":"zEJqCyYQQjSf","executionInfo":{"status":"aborted","timestamp":1681334558887,"user_tz":240,"elapsed":6,"user":{"displayName":"Patrick Wang","userId":"09514208081734500853"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# def valid(model, testing_loader):\n","#     model.eval()\n","#     n_correct = 0; n_wrong = 0; total = 0\n","#     with torch.no_grad():\n","#         for _, data in enumerate(testing_loader, 0):\n","#             ids = data['ids'].to(device, dtype = torch.long)\n","#             mask = data['mask'].to(device, dtype = torch.long)\n","#             targets = data['targets'].to(device, dtype = torch.long)\n","#             outputs = model(ids, mask).squeeze()\n","#             loss = loss_function(outputs, targets)\n","#             tr_loss += loss.item()\n","#             big_val, big_idx = torch.max(outputs.data, dim=1)\n","#             n_correct += calcuate_accu(big_idx, targets)\n","\n","#             nb_tr_steps += 1\n","#             nb_tr_examples+=targets.size(0)\n","            \n","#             if _%5000==0:\n","#                 loss_step = tr_loss/nb_tr_steps\n","#                 accu_step = (n_correct*100)/nb_tr_examples\n","#                 print(f\"Validation Loss per 100 steps: {loss_step}\")\n","#                 print(f\"Validation Accuracy per 100 steps: {accu_step}\")\n","#     epoch_loss = tr_loss/nb_tr_steps\n","#     epoch_accu = (n_correct*100)/nb_tr_examples\n","#     print(f\"Validation Loss Epoch: {epoch_loss}\")\n","#     print(f\"Validation Accuracy Epoch: {epoch_accu}\")\n","    \n","#     return epoch_accu\n"],"metadata":{"id":"MHTSY6G3Qpwz","executionInfo":{"status":"aborted","timestamp":1681334558887,"user_tz":240,"elapsed":6,"user":{"displayName":"Patrick Wang","userId":"09514208081734500853"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# print('This is the validation section to print the accuracy and see how it performs')\n","# print('Here we are leveraging on the dataloader crearted for the validation dataset, the approcah is using more of pytorch')\n","\n","# acc = valid(model, testing_loader)\n","# print(\"Accuracy on test data = %0.2f%%\" % acc)"],"metadata":{"id":"c1PKpQP4Qrtr","executionInfo":{"status":"aborted","timestamp":1681334558888,"user_tz":240,"elapsed":7,"user":{"displayName":"Patrick Wang","userId":"09514208081734500853"}}},"execution_count":null,"outputs":[]}]}